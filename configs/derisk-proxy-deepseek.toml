[system]
# Load language from environment variable(It is set by the hook)
language = "${env:DERISK_LANG:-zh}"
api_keys = []
encrypt_key = "your_secret_key"

# Server Configurations
[service.web]
host = "0.0.0.0"
port = 7777
enable_mcp_gateway="True"
main_app_code = "chat_normal"

[service.web.database]
type = "sqlite"
path = "pilot/meta_data/derisk.db"

[service.model.worker]
host = "127.0.0.1"

[rag]
chunk_size=1000
chunk_overlap=0
similarity_top_k=5
similarity_score_threshold=0.0
max_chunks_once_load=10
max_threads=1
rerank_top_k=3
graph_community_summary_enabled="True"
enable_summary=true

[rag.storage]
[rag.storage.vector]
type = "chroma"
persist_path = "pilot/data"

# Model Configurations
# Model Configurations
[models]
[[models.llms]]
name = "Qwen/QwQ-32B"
provider = "proxy/siliconflow"
api_key = "sk-ehxqemvsxsecymufhqcjqtxxdgmlfkzcpmghtktlcmglvzvp"

[[models.llms]]
#name = "${env:LLM_MODEL_NAME:-deepseek-chat}"
name = "deepseek-chat"
provider = "proxy/deepseek"
api_key = "${env:DEEPSEEK_API_KEY}"



[[models.llms]]
name = "Qwen2.5-72B-Instruct"
provider = "proxy/gitee"
api_key = "W7LRHBLWM0XMW0AGLDRKEITZNZCSUUHAVFOYWO1C"
[[models.llms]]
name = "${env:LLM_MODEL_NAME:-gpt-4o}"
provider = "${env:LLM_MODEL_PROVIDER:-proxy/openai}"
api_base = "${env:OPENAI_API_BASE:-https://api.openai.com/v1}"
api_key = "${env:OPENAI_API_KEY}"

[[models.embeddings]]
name = "bge-large-zh-v1.5"
provider = "proxy/openai"
api_url = "https://ai.gitee.com/v1/embeddings"
api_key = "W7LRHBLWM0XMW0AGLDRKEITZNZCSUUHAVFOYWO1C"
